{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Sigmoid activation function\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "# Softmax function for the output layer\n",
        "def softmax(x):\n",
        "    e_x = np.exp(x - np.max(x, axis=1, keepdims=True))  # Stability\n",
        "    return e_x / np.sum(e_x, axis=1, keepdims=True)\n",
        "\n",
        "# XOR input data\n",
        "X = np.array([[1, 0], [0, 1], [0, 0], [1, 1]])  # Four possible inputs for XOR\n",
        "y = np.array([1, 1, 0, 0])  # Labels for XOR\n",
        "\n",
        "# First layer parameters based on the notes\n",
        "beta1 = np.array([[1, 1]])  # Values for beta^{[1]} (reshaped to 1x2)\n",
        "alpha1 = np.array([0, -1])  # Values for alpha^{[1]} (bias term, shape (2,))\n",
        "\n",
        "# Second layer parameters (for softmax output layer)\n",
        "gamma = np.array([1.1, -1])  # Values for gamma\n",
        "nu = np.array([-0.3])    # Values for nu\n",
        "\n",
        "# Compute z^{[1]} for each input X\n",
        "def forward_first_layer(X, beta1, alpha1):\n",
        "    z1 = np.dot(X, beta1.T) + alpha1  # Corrected to make shapes match\n",
        "    a1 = sigmoid(z1)  # Apply sigmoid activation\n",
        "    return a1\n",
        "\n",
        "# Compute final softmax output\n",
        "def forward_second_layer(a1, gamma, nu):\n",
        "    z2 = np.dot(a1, gamma) + nu  # Final transformation before softmax\n",
        "    return z2  # No softmax needed as we're just using sigmoid later\n",
        "\n",
        "# Forward pass through the first layer (sigmoid)\n",
        "a1 = forward_first_layer(X, beta1, alpha1)\n",
        "\n",
        "# Forward pass through the second layer (linear + sigmoid)\n",
        "z2 = forward_second_layer(a1, gamma, nu)\n",
        "softmax_output = sigmoid(z2)  # Apply sigmoid for final classification probability\n",
        "print(\"Final Output after sigmoid transformation:\", softmax_output)\n",
        "\n",
        "# Classification based on thresholding\n",
        "predictions = (softmax_output > 0.5).astype(int)\n",
        "print(\"Final predictions (class 1 probability > 0.5):\", predictions)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6s_1cnpNNov",
        "outputId": "daf3ea5f-a8c5-4dad-bb60-60bb947ab923"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Output after sigmoid transformation: [0.50104111 0.50104111 0.49526479 0.48445956]\n",
            "Final predictions (class 1 probability > 0.5): [1 1 0 0]\n"
          ]
        }
      ]
    }
  ]
}
